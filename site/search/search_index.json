{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Applied Data Science","text":"<p>Here you'll learn all about Applied Data Science in a practical manner https://deepsai8.github.io/dsapp/.</p>"},{"location":"#links","title":"Links","text":""},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file .\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"#plotly-plots","title":"Plotly plots","text":"{     \"data\": [         {             \"x\": [\"giraffes\", \"orangutans\", \"monkeys\"],             \"y\": [20, 14, 23],             \"type\": \"bar\"         }     ] }"},{"location":"#plotly-plot-2","title":"Plotly plot 2","text":"{     \"data\": [         {             \"x\": [\"raccoons\", \"pandas\", \"wolves\"],             \"y\": [2, 20, 5],             \"type\": \"bar\"         }     ] }"},{"location":"#initial-thoughts","title":"Initial Thoughts","text":""},{"location":"#initial-thoughts_1","title":"Initial Thoughts:","text":""},{"location":"#ill-try-to-make-things-as-intuitive-as-possible","title":"I'll try to make things as intuitive as possible!","text":""},{"location":"markmap_01/","title":"Markmap","text":""},{"location":"blogs/","title":"Index","text":""},{"location":"blogs/#blogs-here","title":"Blogs here","text":""},{"location":"deeplearning/nn/","title":"Neural Networks","text":""},{"location":"deeplearning/nn/#why","title":"Why","text":"<p>Hand engineered features are time consuming, brittle and are not scalable. Can we learn underlying features directly from the data that we have?</p>"},{"location":"deeplearning/nn/#why-now","title":"Why Now?","text":"<p>Big Data + GPU + Software (pytorch, keras, tf) * Progression:     - 1952: SGD     - 1995: CNN</p>"},{"location":"probstats/probability/","title":"Probability Theory","text":""},{"location":"probstats/probability/#a-little-bit-of-history","title":"A little bit of History","text":"<p>The modern mathematical theory of probability has its roots in attempts to analyze games of chance by Gerolamo Cardano in the sixteenth century, and by Pierre de Fermat and Blaise Pascal in the seventeenth century (for example the \"problem of points\"). Christiaan Huygens published a book on the subject in 1657. In the 19th century, what is considered the classical definition of probability was completed by Pierre Laplace 1</p>"},{"location":"probstats/probability/#probability","title":"Probability","text":"<p>In science, the probability of an event is a number that indicates how likely the event is to occur. It is expressed as a number in the range from 0 and 1, or, using percentage notation, in the range from 0% to 100%. The more likely it is that the event will occur, the higher its probability.</p>"},{"location":"probstats/probability/#aximoatic-theory","title":"Aximoatic Theory","text":""},{"location":"probstats/probability/#definitions","title":"Definitions","text":""},{"location":"probstats/probability/#deterministic-system","title":"Deterministic System","text":"<p>In mathematics, computer science and physics, a deterministic system is a system in which no randomness is involved in the development of future states of the system. A deterministic model will thus always produce the same output from a given starting condition or initial state.2</p>"},{"location":"probstats/probability/#random-experiment","title":"Random Experiment","text":"<ul> <li>It's a process or an outcome that is not deterministic, i.e. it is stoichastic</li> <li>e.g. \\(f(x) = x^{2}\\) <ul> <li>or fixed input =&gt; fixed output, meaning deterministic</li> </ul> </li> <li>e.g. <ul> <li>Roll a die (6 possibilities)</li> <li>dealing a deck of cards (52! permutations)</li> </ul> </li> </ul>"},{"location":"probstats/probability/#sample-space","title":"Sample Space","text":"<ul> <li>A set of all possible outcomes of a random experiment, typically denoted by S or \\(\\Omega\\)</li> </ul>"},{"location":"probstats/probability/#elements-or-outcomes-or-atoms-or-singletons","title":"Elements or Outcomes (or Atoms or Singletons)","text":"<ul> <li>These are the outcomes. Usually denoted by small 's' or \\(\\omega\\)</li> <li>e.g. Flip a coin 3 times (order matters), will have these outcomes or elements:<ul> <li>HHH, HHT, HTH, HHT, THH, HTT, THT, TTH, TTT</li> </ul> </li> <li>and set1 = {HHH, HHT, HTH} or set2 = {THH, TTH, TTT} or set3 = {TTT} are the events</li> <li>Above entire set of possible outcomes is called a Descrete Random Experiment</li> </ul>"},{"location":"probstats/probability/#event","title":"Event","text":"<ul> <li>Typically denoted by capital letters A, B etc.</li> <li>It is sort of a subset of S, that can be passed on to a probability measure</li> <li>All set operations can be used to build events</li> </ul>"},{"location":"probstats/probability/#probability-measure","title":"Probability Measure","text":"<ul> <li>A notation such as P(A) = P(X&gt;5) is called a probability measure if it satisfies the 3 Axioms of Kolmogorov</li> </ul>"},{"location":"probstats/probability/#kolmogorov-axioms","title":"Kolmogorov Axioms","text":"<p>The Kolmogorov axioms are the foundations of probability theory introduced by Russian mathematician Andrey Kolmogorov in 1933 3. These axioms remain central and have direct contributions to mathematics, the physical sciences, and real-world probability cases. An alternative approach to formalising probability, favoured by some Bayesians, is given by Cox's theorem</p> <ul> <li>Framework: <ul> <li>let S be a sample space for some Random Experiment</li> <li>let P be a function from P : P(S) -&gt; R</li> <li>here, P(S) = Power set = {set of all subsets of S}</li> <li>we say that P is a probabilty measure ans (S, P) is a probabilty space, if the following 3 axioms are satisfied:</li> </ul> </li> </ul>"},{"location":"probstats/probability/#axioms","title":"Axioms","text":"<ul> <li>\\(P(A)\\geq0\\), for any event \\(A \\subseteq S\\)<ul> <li>aka Non-Negativity</li> </ul> </li> <li>P(S) = 1<ul> <li>aka Unitarity or Unity</li> </ul> </li> <li>If \\(A_{1}, A_{2}, ...\\) is a sequence of Mutually Exclusive events, then \\(P\\left(\\bigcup _{i=1}^{\\infty }A_{i}\\right)=\\sum _{i=1}^{\\infty }P(A_{i})\\)<ul> <li>aka \\(\\sigma\\)-Additivity</li> </ul> </li> </ul> <ol> <li> <p>Probabilistic Expectation \u21a9</p> </li> <li> <p>Deterministic System wikipedia \u21a9</p> </li> <li> <p>Foundations of the theory of probability \u21a9</p> </li> <li> <p>By Tim Stellmach - Own work using Inkscape and Open Office Draw software., Public Domain, https://commons.wikimedia.org/w/index.php?curid=1220091 \u21a9</p> </li> </ol>"}]}